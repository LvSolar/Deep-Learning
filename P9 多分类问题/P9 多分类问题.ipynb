{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1 一些细碎代码\n",
    "### 1.1 Cross Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "一个样本的交叉熵，使用**numpy**实现："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9729189131256584 [0.37797814 0.34200877 0.28001309]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array([1, 0, 0])  # one-hot编码，该样本属于第一类\n",
    "z = np.array([0.2, 0.1, -0.1])  # 线性输出\n",
    "y_pred = np.exp(z) / np.exp(z).sum()  # 经softmax处理\n",
    "loss = (-y * np.log(y_pred)).sum()\n",
    "print(loss, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "同样一个样本的交叉熵，使用**torch**实现:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9729)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "y = torch.LongTensor([0])  # 该样本属于第一类\n",
    "z = torch.tensor([[0.2, 0.1, -0.1]])  # 线性输出\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 使用交叉熵损失\n",
    "loss = criterion(z, y)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Mini-batch: batch_size=3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1= 0.4966353178024292 \n",
      "Batch Loss2= 1.2388995885849\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "Y = torch.LongTensor([2, 0, 1])  #这里有三个样本，每个样本的类别分别为2,0,1\n",
    "# 第一种预测的线性输出，并不是概率。跟上面的z一样，只是这里有三个样本\n",
    "Y_pred1 = torch.Tensor([[0.1, 0.2, 0.9],  # 2\n",
    "                        [1.1, 0.1, 0.2],  # 0\n",
    "                        [0.2, 2.1, 0.1]])  # 1\n",
    "# 第二种预测的线性输出\n",
    "Y_pred2 = torch.Tensor([[0.8, 0.2, 0.3],  # 0\n",
    "                        [0.2, 0.3, 0.5],  # 2\n",
    "                        [0.2, 0.2, 0.5]])  # 2\n",
    "\n",
    "l1 = criterion(Y_pred1, Y)\n",
    "l2 = criterion(Y_pred2, Y)\n",
    "print(\"Batch Loss1=\", l1.item(), \"\\nBatch Loss2=\", l2.item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 示例"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这是一个使用PyTorch实现的简单的神经网络模型，用于对MNIST手写数字进行分类。代码主要包含以下几个部分：\n",
    "\n",
    "1. **数据准备**：使用PyTorch的DataLoader加载MNIST数据集，对数据进行预处理，如将图片转为Tensor，并进行标准化。\n",
    "2. **模型设计**：设计一个包含5个线性层和ReLU激活函数的神经网络模型，最后一层输出10个类别的概率分布。\n",
    "3. **损失和优化器**：定义交叉熵损失函数和SGD优化器，用于训练模型。\n",
    "4. **训练和测试**：使用训练数据对模型进行训练，使用测试数据对模型进行测试，输出准确率。\n",
    "\n",
    "在训练过程中，每300个batch打印一次平均loss；在测试过程中，使用with torch.no_grad()上下文管理器关闭梯度计算，以提高测试效率。最终输出模型在测试集上的准确率。在该模型中，准确率最高为97%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 2.166\n",
      "[1,   600] loss: 0.767\n",
      "[1,   900] loss: 0.385\n",
      "Accuracy on test set: 90 %\n",
      "[2,   300] loss: 0.307\n",
      "[2,   600] loss: 0.262\n",
      "[2,   900] loss: 0.232\n",
      "Accuracy on test set: 93 %\n",
      "[3,   300] loss: 0.192\n",
      "[3,   600] loss: 0.164\n",
      "[3,   900] loss: 0.159\n",
      "Accuracy on test set: 95 %\n",
      "[4,   300] loss: 0.133\n",
      "[4,   600] loss: 0.118\n",
      "[4,   900] loss: 0.119\n",
      "Accuracy on test set: 96 %\n",
      "[5,   300] loss: 0.100\n",
      "[5,   600] loss: 0.094\n",
      "[5,   900] loss: 0.094\n",
      "Accuracy on test set: 97 %\n",
      "[6,   300] loss: 0.074\n",
      "[6,   600] loss: 0.078\n",
      "[6,   900] loss: 0.074\n",
      "Accuracy on test set: 97 %\n",
      "[7,   300] loss: 0.062\n",
      "[7,   600] loss: 0.060\n",
      "[7,   900] loss: 0.058\n",
      "Accuracy on test set: 97 %\n",
      "[8,   300] loss: 0.048\n",
      "[8,   600] loss: 0.049\n",
      "[8,   900] loss: 0.050\n",
      "Accuracy on test set: 97 %\n",
      "[9,   300] loss: 0.040\n",
      "[9,   600] loss: 0.040\n",
      "[9,   900] loss: 0.041\n",
      "Accuracy on test set: 97 %\n",
      "[10,   300] loss: 0.033\n",
      "[10,   600] loss: 0.032\n",
      "[10,   900] loss: 0.032\n",
      "Accuracy on test set: 97 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1、准备数据集\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([  # 一系列的操作，Compose将其组合在一起\n",
    "    transforms.ToTensor(),  # 将图片转为Tensor，并且转换为CHW，即C*H*W，C为通道数，H为高，W为宽，这里为1*28*28\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # 标准化到[0,1]，均值和方差\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='../P6 逻辑斯谛回归/data',\n",
    "                               train=True,\n",
    "                               download=False,  # 在P6 逻辑斯谛回归中我已下载，这里直接读取即可\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST(root='../P6 逻辑斯谛回归/data',\n",
    "                              train=False,\n",
    "                              download=False,\n",
    "                              transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)  # 测试集设置为False，方便观察结果\n",
    "\n",
    "\n",
    "# 2、设计模型\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # 将图片展开为一维向量\n",
    "        x = F.relu(self.l1(x))  # 激活函数\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)  # 最后一层不需要激活函数，因为交叉熵损失函数会对其进行处理\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# 3、构建损失和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)  # 优化器,lr为学习率，momentum为动量\n",
    "\n",
    "\n",
    "# 4、训练和测试\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)  # outputs并不是概率，而是线性层的输出，但其大小顺序与概率分布相同\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:  # 每300个batch打印一次平均loss\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 测试过程中不需要计算梯度\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)  # 返回每一行中最大值的那个元素，以及其索引\n",
    "            total += labels.size(0)  # labels的size为[64]，即64个样本\n",
    "            correct += (predicted == labels).sum().item()  # 统计预测正确的样本个数\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 作业"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 任务描述：\n",
    "Otto Group 是全球最大的电子商务公司之一，在 20 多个国家/地区设有子公司，包括 Crate & Barrel（美国）、Otto.de（德国）和 3 Suisses（法国）。我们每天在全球销售数百万种产品，并且有数千种产品被添加到我们的产品线中。\n",
    "\n",
    "对我们产品的性能进行一致的分析至关重要。然而，由于我们多样化的全球基础设施，许多相同的产品会得到不同的分类。因此，我们产品分析的质量在很大程度上取决于对相似产品进行准确聚类的能力。分类越好，我们对产品系列的洞察力就越多。\n",
    "\n",
    "对于本次比赛，我们提供了一个包含 200,000 多种产品的 93 个特征的数据集。目标是建立一个能够区分我们主要产品类别的预测模型。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 查看数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 导入相关库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 先了解一下数据的基本情况，再进行我们后面的建模流程\n",
    "data = pd.read_csv('../Data/otto/train.csv')\n",
    "data.head()  #查看前五行\n",
    "data.info()  #查看数据信息\n",
    "data.describe()  #查看数据统计信息\n",
    "data.isnull().sum()  #查看缺失值\n",
    "data['target'].value_counts()  #查看各个类别的数量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**数据信息**：完整的数据集包含 93 个特征和 1 个目标变量。目标变量是一个类别变量，包含 9 个类别。每个类别的数量都不相同，但是每个类别的数量都超过 10,000 个。数据集中没有缺失值。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 进行建模"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1000] loss: 0.537\n",
      "[10,  1000] loss: 0.497\n",
      "[15,  1000] loss: 0.480\n",
      "[20,  1000] loss: 0.462\n",
      "[25,  1000] loss: 0.447\n"
     ]
    }
   ],
   "source": [
    "# 1、准备数据\n",
    "class OttoDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('../Data/otto/train.csv', delimiter=',', skiprows=1, usecols=np.arange(1, 94))\n",
    "        df = pd.read_csv('../Data/otto/train.csv', sep=',')\n",
    "        df['target'] = df['target'].map({'Class_1': 1, 'Class_2': 2,  #通过映射将类别转换为数字\n",
    "                                         'Class_3': 3, 'Class_4': 4,\n",
    "                                         'Class_5': 5, 'Class_6': 6,\n",
    "                                         'Class_7': 7, 'Class_8': 8,\n",
    "                                         'Class_9': 9})\n",
    "        df['target'] = df['target'].astype('float')\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, :])\n",
    "        self.y_data = torch.tensor(df['target'].values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "dataset = OttoDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# 2、构建模型\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(93, 64)\n",
    "        self.l2 = torch.nn.Linear(64, 32)\n",
    "        self.l3 = torch.nn.Linear(32, 16)\n",
    "        self.l4 = torch.nn.Linear(16, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        return self.l4(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# 3、构建损失和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.5)\n",
    "\n",
    "\n",
    "# 4、训练模型\n",
    "def train(epoch):\n",
    "    model.train()  #开启训练模式\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.float(), labels.long()\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)  # 是线性层的输出值，不是概率值\n",
    "        loss = criterion(outputs, labels - 1)  #因为类别是从1开始的，所以要减1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (epoch % 5 == 0) and batch_idx % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch, batch_idx + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "# 5、进行预测并保存结果\n",
    "def test():\n",
    "    model.eval()  # 开启测试模式\n",
    "    xyTest = np.loadtxt('../Data/otto/test.csv', delimiter=',', skiprows=1, usecols=np.arange(1, 94))\n",
    "    df1 = pd.read_csv('../Data/otto/test.csv', sep=',')\n",
    "    xy_pred = torch.from_numpy(xyTest[:, :])  # 将测试集转换为tensor\n",
    "    column_list = ['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5',\n",
    "                   'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "    d = pd.DataFrame(0, index=np.arange(xy_pred.shape[0]), columns=column_list)  # 创建一个空的DataFrame\n",
    "    d.iloc[:, 1:] = d.iloc[:, 1:].astype('float')\n",
    "    d['id'] = df1['id']  # 将id列赋值\n",
    "\n",
    "    output = model(xy_pred.clone().detach().requires_grad_(True).float())\n",
    "    row = F.softmax(output, dim=1).data  # 将输出值转换为概率值。注意维度为1\n",
    "    classes = row.numpy()  # 将tensor转换为numpy\n",
    "    classes = np.around(classes, decimals=2)  # 保留两位小数\n",
    "    d.iloc[:, 1:] = classes  # 将概率值赋值给DataFrame\n",
    "    d.to_csv('Submission.csv', index=False)  # 保存结果\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(1, 30):\n",
    "        train(epoch)\n",
    "    test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 总结\n",
    "\n",
    "该代码是一个简单的 PyTorch 神经网络模型，用于分类 Otto 数据集中的产品。这个数据集包含来自九个不同类别的93个特征，共计约60,000个产品。\n",
    "\n",
    "代码的执行分为以下几个步骤：\n",
    "\n",
    "1.数据准备：首先读取 Otto 数据集，然后将类别映射为数字，将数据集划分为输入数据和标签数据，最后使用 PyTorch 中的 DataLoader 将数据集分成多个小批量。\n",
    "\n",
    "2.构建模型：构建了一个简单的四层全连接神经网络，输入层有93个特征，输出层有9个类别。\n",
    "\n",
    "3.构建损失和优化器：选择了交叉熵损失作为损失函数，使用随机梯度下降算法作为优化器。\n",
    "\n",
    "4.训练模型：每次迭代一个 epoch，使用小批量数据进行训练，输出训练的损失值，直到训练完所有的 epoch。\n",
    "\n",
    "5.进行预测并保存结果：使用模型进行预测并保存结果到本地文件。\n",
    "\n",
    "该代码使用 PyTorch 库中的张量 (Tensor) 和自动微分 (autograd) 来实现反向传播算法，这些功能使得神经网络的实现更加简单和高效。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}